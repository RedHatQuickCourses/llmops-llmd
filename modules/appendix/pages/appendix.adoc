// PAGE 7: THE LINGO - SPEAK LIKE A PRO
//======================================================================

[NOTE.nerd_face]
.The Official LLM-D Glossary
====
Impress your colleagues with your deep knowledge of distributed inference terminology.
====

[cols="1,1,3"]
|===
| Icon | Term | Definition

| âš™ï¸
| **CRD**
| Custom Resource Definition. The way you teach Kubernetes new tricks, like understanding what a `ModelService` is.

| ğŸ“¡
| **GIE**
| Gateway API Inference Extension. A special add-on for the Kubernetes Gateway API that makes it AI-aware.

| ğŸ§ 
| **Inference Scheduler**
| The "Genius" component. The brain of the operation that intelligently routes requests.

| âš¡
| **TTFT**
| Time-To-First-Token. The critical "need for speed" metric. How fast does the user see the first word?

| ğŸ’¸
| **TCO**
| Total Cost of Ownership. The number your CFO really cares about. LLM-D is designed to shrink this number.

| ğŸ¤–
| **MoE**
| Mixture-of-Experts. A type of mega-model with specialized "expert" neural networks inside.
|===