= Mission Recovery: Troubleshooting & FAQs
:toc: macro
:toc-title: Diagnostic Playbook

// Header Image placeholder
image::https://www.redhat.com/cms/managed-files/styles/wysiwyg_full_width/s3/Standard%20Logo.png?itok=media_token[Red Hat OpenShift AI, 200, align="left"]

[ABSTRACT]
**Role:** Reliability Engineer (SRE)
**Objective:** Diagnose and resolve common blocking issues during distributed inference deployment.

---

== Common Deployment Blockers

Distributed systems can be fragile during setup. Use this playbook to resolve the most common "Gotchas" encountered in the field.

=== Issue 1: Pods Stuck in "Pending" State
* **Symptom:** You deploy the model, but the pods (specifically `ms-kv-events-llm-d-modelservice-decode`) remain in `Pending` status indefinitely.
* **Diagnosis:** This often happens on nodes with specific Taints (e.g., `NVIDIA-L40S-PRIVATE`) where the standard deployment lacks the matching **Toleration**.
* **Fix:** Patch the deployment to add the required toleration.

[source,bash]
----
oc patch deployment ms-kv-events-llm-d-modelservice-decode \
  -p '{"spec":{"template":{"spec":{"tolerations":[{"key":"nvidia.com/gpu", "operator": "Equal", "value": "NVIDIA-L40S-PRIVATE", "effect": "NoSchedule"}]}}}}'
----

=== Issue 2: MachineSets Scaling Unexpectedly
* **Symptom:** Your GPU MachineSet scales down to 1 replica, or nodes go offline intermittently.
* **Diagnosis:** In lab environments using Spot Instances, the cluster autoscaler may aggressively scale down if it detects idle periods during setup.
* **Fix:** Manually enforce the replica count (ensure you have 2 nodes for Disaggregated labs).

[source,bash]
----
# Replace with your specific machineset name
oc scale machineset <gpu-machineset-name> -n openshift-machine-api --replicas=2
----

=== Issue 3: "Gateway Address Pending"
* **Symptom:** When running `oc get gateways`, the `ADDRESS` column remains empty.
* **Diagnosis:** The underlying Service Mesh (Istio) Load Balancer has not been assigned an IP by the cloud provider.
* **Fix:** Check the Istio Ingress Gateway status. If it hangs, verify you haven't exceeded your cloud account's Load Balancer quota.

[source,bash]
----
oc get svc -n istio-system
----

=== Issue 4: 403 Forbidden on Inference Requests
* **Symptom:** You receive a `403 Forbidden` error when `curl`-ing the endpoint, even though the pod is running.
* **Diagnosis:** **Authorino** is active and blocking the request because the `Authorization` header is missing or invalid.
* **Fix:** You must generate and pass a valid ServiceAccount token.

[source,bash]
----
export TOKEN=$(oc create token default -n <namespace>)
curl -H "Authorization: Bearer $TOKEN" ...
----