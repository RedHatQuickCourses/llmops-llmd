= OpenShift AI 3.0 Release Notes

[NOTE]
.OpenShift AI 3.0 Summarized Release Notes for this course
====

*Supported Features in Red Hat OpenShift AI 3.0 and llm-d:*

 *   **User Interface (UI) for Deployment:** OpenShift AI now includes a user interface for configuring and deploying Large Language Models (LLMs) on the `llm-d` Serving Runtime. This streamlined interface simplifies common deployment scenarios by offering essential configuration options with sensible defaults, while still allowing explicit selection of the `llm-d` runtime.
 *   **Observability and Grafana Integration:** Platform administrators can now connect observability components to Distributed Inference with `llm-d` deployments. This allows integration with self-hosted Grafana instances for monitoring inference workloads. Teams can collect and visualize Prometheus metrics from `llm-d` for performance analysis and custom dashboard creation.
 *   **Model-as-a-Service (MaaS) Support:** MaaS is currently supported only for models deployed using the Distributed Inference Server with `llm-d` runtime.

*The following capabilities are not fully supported in OpenShift AI 3.0:*

 * Wide Expert-Parallelism multi-node: Developer Preview.
 * Wide Expert-Parallelism on Blackwell B200: Not available but can be provided as a Technology Preview.
 * Multi-node on GB200: Not supported.
 * Gateway discovery and association are not supported in the UI during model deployment in this release. Users must associate models with Gateways by applying the resource manifests directly through the API or CLI.


*llm-d Known Issues in OpenShift AI 3.0:*

 *   While Distributed Inference Server with llm-d appears as an available option for deployment, it is not currently listed on the Serving Runtimes page under the Settings section.
 *   Models deployed using llm-d initially display a *Failed* status on the Deployments page in the OpenShift AI dashboard, even if associated pod logs report no errors or failures; the status automatically updates to *Started* when the model is ready.
====