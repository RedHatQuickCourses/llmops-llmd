<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Lab Demo: Your Interactive Guide to llm-d Deployment :: Maximize Your GPU ROI, Scaling LLM Inference llm-d</title>
    <link rel="prev" href="benefits.html">
    <link rel="next" href="summary.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">Maximize Your GPU ROI, Scaling LLM Inference llm-d</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="llmops-llmd" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Maximize Your GPU ROI, Scaling LLM Inference llm-d</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="redhatai.html">AI Factory on Red Hat AI</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="vllmllmd.html">The Scalable LLM Inference Stack: vLLM &amp; llm-d</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="llmdarch.html">llm-d Architecture Deep Dive: Building the Foundation</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="benefits.html">llm-d Use Cases and Core Benefits</a>
  </li>
  <li class="nav-item is-current-page" data-depth="1">
    <a class="nav-link" href="walkthrough.html">Lab Demo: Your Interactive Guide to llm-d Deployment</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="summary.html">Course Summary</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../appendix/appendix.html">appendix</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/index.html">Taxonomy to Know</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/kvcache.html">Deep Dive on KV Cache Management</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/lws.html">LeaderWorkerSet (LWS) Operator</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/trbleshoot.html">Troubleshooting</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Maximize Your GPU ROI, Scaling LLM Inference llm-d</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Maximize Your GPU ROI, Scaling LLM Inference llm-d</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Maximize Your GPU ROI, Scaling LLM Inference llm-d</a></li>
    <li><a href="walkthrough.html">Lab Demo: Your Interactive Guide to llm-d Deployment</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Lab Demo: Your Interactive Guide to llm-d Deployment</h1>
<div class="sect1">
<h2 id="_your_starting_point_the_arcade_experience"><a class="anchor" href="#_your_starting_point_the_arcade_experience"></a>Your Starting Point: The Arcade Experience</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Welcome to the interactive labs! Before we dive deep into hands-on technical configurations in the next course, we want to give you a "flight simulator" experience of what it&#8217;s like to work with OpenShift AI.</p>
</div>
<div class="paragraph">
<p>We are using Arcade walkthroughs here to provide a guided, high-speed tour of the entire process—from ordering a lab environment to deploying a Generative AI model using distributed inference with llm-d. This lets you explore the workflow and understand the "big picture" steps without worrying about resource costs or waiting for provisioning times.</p>
</div>
<div class="paragraph">
<p>Ready to see how it all comes together? Let&#8217;s jump in.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_1_requesting_your_lab_environment"><a class="anchor" href="#_1_requesting_your_lab_environment"></a>1. Requesting Your Lab Environment</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Every great project starts with the right infrastructure. In this first interactive segment, we&#8217;ll walk through the process of requesting a lab environment from the Red Hat Demo Platform (RHDP) catalog.</p>
</div>
<div class="paragraph">
<p>Think of this as ordering the raw materials for your AI factory. We&#8217;ll show you how to select the right OpenShift AI cluster configuration. You&#8217;ll see options for different GPU sizes—from standard setups suitable for smaller models to massive multi-GPU nodes designed for large-scale inter-GPU scenarios.</p>
</div>
<div class="paragraph">
<p>Don&#8217;t worry about the costs right now; this simulation just shows you how to make those choices in a real scenario.</p>
</div>
<div class="paragraph">
<p><a href="https://catalog.demo.redhat.com/catalog?item=babylon-catalog-prod/published.openshift-ai-v3.prod&amp;utm_source=webapp&amp;utm_medium=share-link" target="blank">Red Hat OpenShift AI 3.0 catalog link</a></p>
</div>
<iframe src="https://demo.arcade.software/w6HfuWHzkJ0rx9yXCzQk?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true" width="100%" height="600px" frameborder="0" allowfullscreen webkitallowfullscreen mozallowfullscreen allow="clipboard-write" muted> </iframe>
</div>
</div>
<div class="sect1">
<h2 id="_2_initial_cluster_login_a_quick_tour"><a class="anchor" href="#_2_initial_cluster_login_a_quick_tour"></a>2. Initial Cluster Login &amp; A Quick Tour</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Your environment is ready—now let&#8217;s move in. This segment guides you through your first login to the OpenShift AI 3.0 interface.</p>
</div>
<div class="paragraph">
<p>We&#8217;ll take a brief tour of the new menu options and introduce you to the crucial "Hardware Profiles" section, where you define how compute resources (like GPUs) are carved up for your models. To make sure the foundations are solid, we&#8217;ll also do a quick "smoke test" by deploying a standard Granite model from the catalog, verifying that the basic vLLM inference components are ready for action.</p>
</div>
<iframe src="https://demo.arcade.software/GfqvGnWw1uQdlBhkLhy9?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true" width="100%" height="600px" frameborder="0" allowfullscreen webkitallowfullscreen mozallowfullscreen allow="clipboard-write" muted> </iframe>
</div>
</div>
<div class="sect1">
<h2 id="_3_checking_under_the_hood_openshift_console_configuration"><a class="anchor" href="#_3_checking_under_the_hood_openshift_console_configuration"></a>3. Checking Under the Hood: OpenShift Console Configuration</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Before we deploy complex distributed models, we need to ensure the engine room is prepped. In this walkthrough, we dive down a layer into the OpenShift Container Platform console.</p>
</div>
<div class="paragraph">
<p>This is a pre-flight check. We will verify that the necessary infrastructure Operators are installed—specifically the "Leader Worker Set Operator," which is the secret sauce llm-d uses to manage fleets of pods for distributed inference. We&#8217;ll also confirm that our OpenShift version meets the requirements for these advanced features.</p>
</div>
<iframe src="https://demo.arcade.software/S1dHIjii1Vjkqi0phdSd?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true" width="100%" height="600px" frameborder="0" allowfullscreen webkitallowfullscreen mozallowfullscreen allow="clipboard-write" muted> </iframe>
</div>
</div>
<div class="sect1">
<h2 id="_4_the_main_event_deploying_with_llm_d"><a class="anchor" href="#_4_the_main_event_deploying_with_llm_d"></a>4. The Main Event: Deploying with llm-d</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Everything is configured; it&#8217;s time to deploy. This segment returns to the OpenShift AI console for the main event: deploying a Granite model using the specialized llm-d runtime.</p>
</div>
<div class="paragraph">
<p>You&#8217;ll see just how straightforward the process is. We will select our model files via an existing data connection, choose the appropriate GPU Hardware Profile, and select the llm-d serving runtime.</p>
</div>
<div class="paragraph">
<p>Note: For the purposes of this specific simulation environment, we will disable token authentication to ensure the deployment completes smoothly during the walkthrough.</p>
</div>
<iframe src="https://demo.arcade.software/WDbYI8agiNhgCIfYPLp9?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true" width="100%" height="600px" frameborder="0" allowfullscreen webkitallowfullscreen mozallowfullscreen allow="clipboard-write" muted> </iframe>
</div>
</div>
<div class="sect1">
<h2 id="_5_watching_it_come_alive_monitoring_the_deployment"><a class="anchor" href="#_5_watching_it_come_alive_monitoring_the_deployment"></a>5. Watching it Come Alive: Monitoring the Deployment</h2>
<div class="sectionbody">
<div class="paragraph">
<p>You&#8217;ve clicked "Deploy," but what&#8217;s happening in the background? In this step, we hop back over to the OpenShift Console to watch our distributed service spin up.</p>
</div>
<div class="paragraph">
<p>We aren&#8217;t just looking for one pod anymore. We&#8217;ll check the Topology view and logs to verify that two distinct components are successfully launching: the intelligent scheduler pod and the vLLM-powered inference pod responsible for the heavy lifting.</p>
</div>
<iframe src="https://demo.arcade.software/z3WQEOr7Vd1QrGmxVRQf?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true"  width="100%" height="600px" frameborder="0" allowfullscreen webkitallowfullscreen mozallowfullscreen allow="clipboard-write" muted> </iframe>
</div>
</div>
<div class="sect1">
<h2 id="_6_the_moment_of_truth_validating_the_deployment"><a class="anchor" href="#_6_the_moment_of_truth_validating_the_deployment"></a>6. The Moment of Truth: Validating the Deployment</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The pods are green, but does it actually work? Let&#8217;s find out.</p>
</div>
<div class="paragraph">
<p>In this final interactive experience, we&#8217;ll launch a Jupyter Notebook environment via a Workbench. We&#8217;ll clone a testing repository, point it at our newly created inference endpoint, and send a few distinct queries to the model. This is the final validation that your llm-d deployment is live and correctly responding to requests.</p>
</div>
<iframe src="https://demo.arcade.software/cKkaV0pgSsSJnRM0wRsj?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true" width="100%" height="600px" frameborder="0" allowfullscreen webkitallowfullscreen mozallowfullscreen allow="clipboard-write" muted> </iframe>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="benefits.html">llm-d Use Cases and Core Benefits</a></span>
  <span class="next"><a href="summary.html">Course Summary</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
