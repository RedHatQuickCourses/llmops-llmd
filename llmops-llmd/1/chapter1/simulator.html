<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Simulator: Distributed Inference Operations :: Maximize Your GPU ROI, Scaling LLM Inference llm-d</title>
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">Maximize Your GPU ROI, Scaling LLM Inference llm-d</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="llmops-llmd" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Maximize Your GPU ROI, Scaling LLM Inference llm-d</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="vllmllmd.html">The Distributed Inference Stack: vLLM &amp; llm-d</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="llmdarch.html">Building the Foundation &amp; Request Lifecycle</a>
  </li>
  <li class="nav-item is-current-page" data-depth="1">
    <a class="nav-link" href="simulator.html">Simulator: Distributed Inference Operations</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="labguide.html">Deploying Distributed Inference</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="summary.html">Maximizing ROI &amp; Next Steps</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../appendix/appendix.html">Appendix</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/well-lit-paths.html">The "Well-Lit Paths" of Deployment</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/trbleshoot.html">Troubleshooting &amp; FAQs</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/kvcache.html">Deep Dive: (KV Cache)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/reference.html">Reference &amp; Glossary</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Maximize Your GPU ROI, Scaling LLM Inference llm-d</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Maximize Your GPU ROI, Scaling LLM Inference llm-d</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Maximize Your GPU ROI, Scaling LLM Inference llm-d</a></li>
    <li><a href="simulator.html">Simulator: Distributed Inference Operations</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Simulator: Distributed Inference Operations</h1>
<div id="preamble">
<div class="sectionbody">
<div class="imageblock text-left">
<div class="content">
<img src="_images/llmd-banner.png" alt="Red Hat OpenShift AI" width="200">
</div>
</div>
<div class="paragraph">
<p><strong>Role:</strong> All Personas (No Lab Required)<br>
<strong>Objective:</strong> Execute a complete end-to-end deployment cycle—from infrastructure provisioning to validation—in a guided, risk-free simulation.</p>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_the_interactive_experience"><a class="anchor" href="#_the_interactive_experience"></a>The Interactive Experience</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Welcome to the <strong>Distributed Inference Simulator</strong>. This module provides a high-speed, guided tour of the entire <code>llm-d</code> workflow on Red Hat OpenShift AI 3.0.</p>
</div>
<div class="paragraph">
<p>Use this simulator if:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>You do not have access to a GPU-enabled OpenShift cluster today.</p>
</li>
<li>
<p>You need to validate the "ClickOps" workflow before building automation.</p>
</li>
<li>
<p>You want to see the "Big Picture" operations without waiting for provisioning times.</p>
</li>
</ul>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_phase_1_infrastructure_provisioning"><a class="anchor" href="#_phase_1_infrastructure_provisioning"></a>Phase 1: Infrastructure Provisioning</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Before we deploy models, we must secure the OpenShift AI 3.0 Environment. This simulations use Red Hat demo plaform to provision a RHOAI 3.0 platform.</p>
</div>
<div class="sect2">
<h3 id="_1_1_access_hardware_verification"><a class="anchor" href="#_1_1_access_hardware_verification"></a>1.1 Access &amp; Hardware Verification</h3>
<div class="paragraph">
<p><strong>Task:</strong> Log in to the RHOAI console, review the dashboard menus, inspect the settings for "Hardware Profiles" to understand how allocate physical GPUs for inference, then deploy a model from the RHOAI Model Catalog.</p>
</div>
<iframe src="https://demo.arcade.software/GfqvGnWw1uQdlBhkLhy9?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true" width="100%" height="500px" frameborder="0" allowfullscreen webkitallowfullscreen mozallowfullscreen allow="clipboard-write" muted> </iframe>
</div>
<div class="sect2">
<h3 id="_1_2_operator_health_check"><a class="anchor" href="#_1_2_operator_health_check"></a>1.2 Operator Health Check</h3>
<div class="paragraph">
<p><strong>Task:</strong> From the Openshift Dashboard install the "Leader Worker Set (LWS)" Operator. This is the secret sauce <code>llm-d</code> uses to manage pod fleets.  Next, explore the OpenShift console to validate, OCP version of 4.19 or greater, with 4.20 recommended.  Install the Terminal Operator to interact with our cluster via the command line.</p>
</div>
<iframe src="https://demo.arcade.software/S1dHIjii1Vjkqi0phdSd?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true" width="100%" height="500px" frameborder="0" allowfullscreen webkitallowfullscreen mozallowfullscreen allow="clipboard-write" muted> </iframe>
<hr>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_phase_2_the_distributed_inference_deployment"><a class="anchor" href="#_phase_2_the_distributed_inference_deployment"></a>Phase 2: The Distributed Inference Deployment</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Now that the foundation is solid, we execute the deployment. These simulations show the transition from "Config" to "Running Service."</p>
</div>
<div class="sect2">
<h3 id="_2_1_deploying_with_llm_d"><a class="anchor" href="#_2_1_deploying_with_llm_d"></a>2.1 Deploying with llm-d</h3>
<div class="paragraph">
<p><strong>Task:</strong> Configure the <code>llm-d</code> Serving Runtime, attach the Granite model, and select the distributed hardware profile.</p>
</div>
<iframe src="https://demo.arcade.software/WDbYI8agiNhgCIfYPLp9?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true" width="100%" height="500px" frameborder="0" allowfullscreen webkitallowfullscreen mozallowfullscreen allow="clipboard-write" muted> </iframe>
</div>
<div class="sect2">
<h3 id="_2_2_observability_topology"><a class="anchor" href="#_2_2_observability_topology"></a>2.2 Observability &amp; Topology</h3>
<div class="paragraph">
<p><strong>Task:</strong> Inspect the OpenShift Topology view to confirm the separation of the <strong>Inference Scheduler</strong> (Control Plane) and <strong>vLLM Pods</strong> (Engine). Explore the pods state during the llm-d inference deployment via the OpenShift console.</p>
</div>
<iframe src="https://demo.arcade.software/z3WQEOr7Vd1QrGmxVRQf?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true"  width="100%" height="500px" frameborder="0" allowfullscreen webkitallowfullscreen mozallowfullscreen allow="clipboard-write" muted> </iframe>
<hr>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_phase_3_validation_the_test"><a class="anchor" href="#_phase_3_validation_the_test"></a>Phase 3: Validation (The Test)</h2>
<div class="sectionbody">
<div class="paragraph">
<p>A deployment is only successful if it answers questions.</p>
</div>
<div class="sect2">
<h3 id="_3_1_inference_validation"><a class="anchor" href="#_3_1_inference_validation"></a>3.1 Inference Validation</h3>
<div class="paragraph">
<p><strong>Task:</strong> Launch a Jupyter Notebook, connect to the new inference endpoint, and validate the response and percieved latency.</p>
</div>
<iframe src="https://demo.arcade.software/cKkaV0pgSsSJnRM0wRsj?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true" width="100%" height="500px" frameborder="0" allowfullscreen webkitallowfullscreen mozallowfullscreen allow="clipboard-write" muted> </iframe>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs"></code></pre>
</div>
</div>
</div>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
