<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>LLM-D Technical Reference :: vLLM to AI Factory Scaling with LLM-D</title>
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">vLLM to AI Factory Scaling with LLM-D</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="llmops-llmd" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">vLLM to AI Factory Scaling with LLM-D</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../chapter3/redhatai.html">AI Factory on Red Hat AI</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../chapter3/section1.html">LLM-D Use Cases and Core Benefits</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../chapter3/section2.html">LLM-D Architecture Deep Dive: Building the Foundation</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../chapter3/section6.html">Lab Demo: llm-d Deployment Guide Arcade Experience</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../appendix/appendix.html">Troubleshooting</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/index.html">Taxonomy to Know</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/kvcache.html">Deep Dive on KV Cache Management</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/lws.html">LeaderWorkerSet (LWS) Operator</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">vLLM to AI Factory Scaling with LLM-D</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">vLLM to AI Factory Scaling with LLM-D</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">vLLM to AI Factory Scaling with LLM-D</a></li>
    <li><a href="section1.html">LLM-D Technical Reference</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">LLM-D Technical Reference</h1>
<div id="preamble">
<div class="sectionbody">
<div class="literalblock">
<div class="content">
<pre>  _      _      _       _       ____
 | |    | |    |  \___/  |     |  _ \
 | |    | |    | |\___/| |     | | | |
 | |    | |    | |     | |     | | | |
 | |___ | |___ | |     | |     | | | |
 |_____||_____||_|     |_|     |____/

  USER GUIDE &amp; TECHNICAL REFERENCE</pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_what_is_llm_d"><a class="anchor" href="#_what_is_llm_d"></a>What is LLM-D?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>High Performance Distributed Inference on Kubernetes</p>
</div>
<div class="paragraph">
<p>llm-d is a Kubernetes-native distributed inference serving stack, providing well-lit paths for anyone to serve large generative AI models at scale, with the fastest time-to-value and competitive performance per dollar for most models across most hardware accelerators.</p>
</div>
<div class="paragraph">
<p>It is engineered to transform traditional single-server vLLM deployments into a distributed system, maximizing performance-per-dollar by directly confronting the architectural bottlenecks of LLM workloads.</p>
</div>
<div class="paragraph">
<p>The project&#8217;s goal is providing well-lit paths for enterprises to adopt cutting-edge distributed inference techniques, thereby reducing the Total Cost of Ownership (TCO) and improving Service-Level Objectives (SLOs) for demanding Generative AI applications <strong>for most models across most hardware accelerators</strong>.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>A Little Sidebar&#8230;&#8203;</strong></p>
</div>
<div class="paragraph">
<p>ü§î <strong>"But why should I care?"</strong></p>
</div>
<div class="paragraph">
<p>Simple. LLMs are <strong>expensive</strong>. Every wasted GPU cycle is money down the drain. LLM-D is designed to plug those leaks, letting you serve more users, faster, and for a fraction of the cost. It&#8217;s not just about tech; it&#8217;s about making your AI projects economically viable.</p>
</div>
</div>
</div>
<hr>
<hr>
<iframe
  src="https://demo.arcade.software/DwprD0GQFJ7bwQJBzw9D?embed&embed_mobile=inline&embed_desktop=inline&show_copy_link=true"
  width="100%"
  height="600px"
  frameborder="0"
  allowfullscreen
  webkitallowfullscreen
  mozallowfullscreen
  allow="clipboard-write"
  muted>
</iframe>
<hr>
<div class="admonitionblock note nerd_face">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">The Official LLM-D Glossary</div>
<div class="paragraph">
<p>Impress your colleagues with your deep knowledge of distributed inference terminology.</p>
</div>
</td>
</tr>
</table>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Icon</th>
<th class="tableblock halign-left valign-top">Term</th>
<th class="tableblock halign-left valign-top">Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚öôÔ∏è</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>CRD</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Custom Resource Definition. The way you teach Kubernetes new tricks, like understanding what a <code>ModelService</code> is.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">üì°</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>GIE</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Gateway API Inference Extension. A special add-on for the Kubernetes Gateway API that makes it AI-aware.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">üß†</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Inference Scheduler</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The "Genius" component. The brain of the operation that intelligently routes requests.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚ö°</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>TTFT</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Time-To-First-Token. The critical "need for speed" metric. How fast does the user see the first word?</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">üí∏</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>TCO</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Total Cost of Ownership. The number your CFO really cares about. LLM-D is designed to shrink this number.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ü§ñ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>MoE</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mixture-of-Experts. A type of mega-model with specialized "expert" neural networks inside.</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
