<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>From vLLM to AI Factory: Scaling with LLM-D :: vLLM to AI Factory Scaling with LLM-D</title>
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">vLLM to AI Factory Scaling with LLM-D</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="llmops-llmd" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">vLLM to AI Factory Scaling with LLM-D</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="redhatai.html">AI Factory on Red Hat AI</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="section1.html">LLM-D Use Cases and Core Benefits</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="section2.html">LLM-D Architecture Deep Dive: Building the Foundation</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="section6.html">Lab Demo: llm-d Deployment Guide Arcade Experience</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../appendix/appendix.html">Troubleshooting</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/index.html">Taxonomy to Know</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/kvcache.html">Deep Dive on KV Cache Management</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/lws.html">LeaderWorkerSet (LWS) Operator</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">vLLM to AI Factory Scaling with LLM-D</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">vLLM to AI Factory Scaling with LLM-D</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">vLLM to AI Factory Scaling with LLM-D</a></li>
    <li><a href="index.html">From vLLM to AI Factory: Scaling with LLM-D</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">From vLLM to AI Factory: Scaling with LLM-D</h1>
<div id="preamble">
<div class="sectionbody">
<div class="exampleblock">
<div class="content">
<div class="literalblock">
<div class="content">
<pre>     _      _      _       _       ____
    | |    | |    |  \___/  |     |  _ \
    | |    | |    | |\___/| |     | | | |
    | |    | |    | |     | |     | | | |
    | |___ | |___ | |     | |     | | | |
    |_____||_____||_|     |_|     |____/

  DISTRUBUTED INFERENCE WITH LLM-D</pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="title">Prerequisite Knowledge</div>
This course assumes you are already familiar with the basics of Kubernetes and vLLM Inference. We will be building on those core concepts.
</td>
</tr>
</table>
</div>
<div class="paragraph icon-question-circle">
<p>Why build an "AI Factory" when cheap API tokens exist?</p>
</div>
<div class="paragraph">
<p>This interactive journey shows you why.</p>
</div>
<div class="paragraph">
<p>Discover how OpenShift AI&#8217;s Distributed Inference (powered by LLM-D) gives you what public APIs can&#8217;t: guaranteed performance SLOs, a lower TCO by eliminating GPU waste, and true hybrid cloud security.</p>
</div>
<div class="paragraph">
<p>This course is your "Front Door" to the complete learning path, designed to provide multiple depths of knowledge—from the high-level "Why" for executives and sales to the hands-on "How" for consultants and services.</p>
</div>
<hr>
</div>
</div>
<div class="sect1">
<h2 id="_the_core_challenge_apis_vs_on_premise_ai"><a class="anchor" href="#_the_core_challenge_apis_vs_on_premise_ai"></a>The Core Challenge: APIs vs. On-Premise AI</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Generative AI is transforming industries, but as you move from experiment to production, you face a critical business decision:</p>
</div>
<div class="paragraph icon-question-circle">
<p>"Why should we build, manage, and pay for our own GPU infrastructure when cheap, pay-as-you-go public API tokens exist?"</p>
</div>
<div class="paragraph">
<p>This is the central question this course is designed to answer.</p>
</div>
<div class="paragraph">
<p>A public API offers convenience, but at the cost of control. It&#8217;s a "best-effort" service with unpredictable performance, runaway costs for high-volume tasks, and a critical security blindspot: you must send your most sensitive corporate data to a third party.</p>
</div>
<div class="paragraph">
<p>This course will show you how to build a true "AI Factory" on OpenShift AI, using the power of distributed inference with llm-d to achieve what public APIs cannot.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_what_you_will_learn_the_value_of_an_ai_factory"><a class="anchor" href="#_what_you_will_learn_the_value_of_an_ai_factory"></a>What You Will Learn: The Value of an AI Factory</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This course is your guide to mastering the three pillars of enterprise-grade AI inference. You will learn how llm-d gives you the power to:</p>
</div>
<div class="paragraph">
<div class="title">Optimize Total Cost of Ownership (TCO)</div>
<p>Stop "Paying for Idle GPUs": Learn how llm-d&#8217;s Smart Scheduling (Path 1) replaces basic, "AI-unaware" Kubernetes scheduling. You&#8217;ll see how to eliminate hotspots, balance your cluster, and finally use 100% of the expensive hardware you&#8217;ve already paid for.</p>
</div>
<div class="paragraph">
<p>Maximize GPU Density: Discover how KV Cache Management (Path 4) offloads the model&#8217;s "memory" from expensive GPU VRAM to cheaper CPU RAM, allowing you to run more models on the same hardware.</p>
</div>
<div class="paragraph">
<div class="title">Guarantee Performance &amp; SLOs</div>
<p>Move from "Best Effort" to "Guaranteed": Public APIs offer no performance guarantees. Learn how llm-d&#8217;s Disaggregated Inference (Path 2) separates compute-heavy "Prefill" from memory-fast "Decode" to ensure your interactive applications are always responsive.</p>
</div>
<div class="paragraph">
<p>Master the "Well-Lit Paths": Understand the 4 pre-packaged, Helm-automated deployment patterns that provide optimized, step-by-step solutions for scaling any model, from the simplest to the most complex.</p>
</div>
<div class="paragraph">
<div class="title">Ensure Total Security &amp; Control</div>
<p>Achieve "Sovereign AI": The most critical value-add. Learn how this entire, high-performance stack runs inside your own OpenShift cluster. Your proprietary RAG documents, customer data, and sensitive prompts never leave your control.</p>
</div>
<div class="paragraph">
<p>Own Your Hybrid Cloud Strategy: Deploy a secure, consistent, and performant AI inference platform wherever your data lives—on-premise, in a private cloud, or at the edge.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="title">Prerequisite Knowledge</div>
This course assumes you are already familiar with the basics of Kubernetes and the core concepts of vLLM Inference. We will be building directly on that foundation.
</td>
</tr>
</table>
</div>
<hr>
<div class="paragraph">
<p>This course is a multi-format learning journey. You will find a mix of videos, technical articles, and resource links, but the core of this course is delivered through Interactive Arcades.</p>
</div>
<div class="admonitionblock tip icon-play-circle">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="title">What is an "Arcade"?</div>
An Arcade is an interactive demonstration. You&#8217;ll read the content on each slide and then click on "hotspots" (like blinking dots or text boxes) to move through the presentation. This format is used for both conceptual guides and some lab exercises.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">Pro-Tips for the Best Experience</div>
Here are a few tips to get you started:
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><strong>Go Full Screen:</strong> This is the highly recommended way to use Arcades. Use the "expand" icon (usually in the top-right corner) to ensure hotspots and text don&#8217;t overlap.</p>
</div>
<div class="paragraph">
<p><strong>Navigate:</strong> Use the arrows in the top-left corner to move forward and back through the presentation.</p>
</div>
<div class="paragraph">
<p><strong>Track Your Progress:</strong> The bar at the bottom of the window shows your progression through the interactive segments.</p>
</div>
<div class="paragraph">
<p>If you&#8217;re new to Arcades and would like a visual walkthrough, you can find a helpful video in the appendix.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s begin.</p>
</div>
<div class="paragraph">
<p>This interactive journey answers that question.</p>
</div>
<div class="paragraph">
<p>Public APIs offer convenience, but they fail to answer the three core challenges of enterprise AI: Cost, Performance, and Security.</p>
</div>
<div class="paragraph">
<p>This course is a comprehensive guide to solving all three. You will learn how OpenShift AI and Distributed Inference (powered by llm-d) give you what public APIs cannot:</p>
</div>
<div class="paragraph">
<p>The Best TCO: Learn to eliminate "idle GPU" waste and maximize your hardware investment, drastically lowering your Total Cost of Ownership.</p>
</div>
<div class="paragraph">
<p>Guaranteed Performance: Move from "best effort" to "guaranteed SLOs." Learn how to solve hotspots and ensure a fast, responsive experience for every user.</p>
</div>
<div class="paragraph">
<p>True Hybrid Cloud Security: Master the "Sovereign AI" model. Learn to deploy world-class inference inside your own cluster, keeping your proprietary data 100% secure.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_what_you_will_learn_in_this_course"><a class="anchor" href="#_what_you_will_learn_in_this_course"></a>What You Will Learn in This Course</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This course provides a complete learning path, designed to provide multiple depths of knowledge.</p>
</div>
<div class="paragraph">
<p>Master the "Why": Learn to articulate the business value (TCO, ROI, Security) of on-premise, distributed inference versus public APIs.</p>
</div>
<div class="paragraph">
<p>Explore the "4 Well-Lit Paths": Understand the specific, pre-packaged deployment patterns (llm-d) that solve real-world scaling challenges, from immediate wins to advanced optimization.</p>
</div>
<div class="paragraph">
<p>Get Hands-On with the "How": Move from theory to practice. You will deploy and manage distributed models using the llm-d framework on OpenShift AI.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_who_is_this_course_for"><a class="anchor" href="#_who_is_this_course_for"></a>Who Is This Course For?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This journey is designed for technical professionals who need to design, build, or deploy scalable AI solutions on OpenShift:</p>
</div>
<div class="paragraph">
<p>AI/ML Architects</p>
</div>
<div class="paragraph">
<p>Solutions Architects</p>
</div>
<div class="paragraph">
<p>Consultants &amp; Services</p>
</div>
<div class="paragraph">
<p>Technical Sellers &amp; Pre-Sales</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="title">Prerequisite Knowledge</div>
This course assumes you are already familiar with the basics of Kubernetes and the core concepts of vLLM Inference. We will be building directly on that foundation.
</td>
</tr>
</table>
</div>
<hr>
<div class="paragraph">
<p>Let&#8217;s begin.</p>
</div>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
